{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "import torch.nn.functional as F # for bce loss function\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable, Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "     \n",
    "BATCH_SIZE = 32\n",
    "INPUT_CHANNELS = 12\n",
    "RES_BLOCK_INPUT_CHANNELS = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Prep\n",
    "## III. Data Visualization Methods\n",
    "do we need these??? ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Testing\n",
    "## IV. Evaluation Metrics: done\n",
    "- IoU: Intersection over Union. measures overlap between prediction region and actual (ground truth) region. Scores from 0 to 1, where 1 is perfect overlap and 0 is no overlap. Usually used to determine whether bounding box is correct\n",
    "- Recall\n",
    "- Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IoU metric\n",
    "Calculation of intersection over union metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): IoU metric value\n",
    "\n",
    "CHANGES: \n",
    "    - changed \"tf\" to \"torch\" in method header and real_mask line\n",
    "    - added comments\n",
    "\"\"\"\n",
    "def IoU_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float: \n",
    "    # replacing neg values: torch.where(condition, choose-True, choose-False)\n",
    "    # when the value is pos (>=0), keep the value from real_mastorch. otherwise, replace with 0\n",
    "    real_mask = torch.where(real_mask>=0, real_mask, 0)\n",
    "\n",
    "    # calculates the intersection and union between real and predicted by using a log AND and OR functions from numpy\n",
    "    intersection = np.logical_and(real_mask, predicted_mask)\n",
    "    union = np.logical_or(real_mask, predicted_mask)\n",
    "\n",
    "    # if there is no object in either mask (both are entirely 0s), return 1 since IoU for \n",
    "    # empty masks would be perfect\n",
    "    if np.sum(union) == 0:\n",
    "        return 1\n",
    "    \n",
    "    # else, calculate and return intersection over union (IoU)\n",
    "    return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculation of recall metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): recall metric value\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "\"\"\"\n",
    "def recall_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float:\n",
    "\n",
    "    real_mask = torch.where(real_mask < 0, 0, real_mask)\n",
    "    \n",
    "    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n",
    "    actual_positives = np.sum(real_mask)\n",
    "    if actual_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    return true_positives / actual_positives\n",
    "\n",
    "\"\"\"\n",
    "Calculation of precision metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): precision metric value\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "\"\"\"\n",
    "def precision_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float:\n",
    "    real_mask = torch.where(real_mask < 0, 0, real_mask)\n",
    "    \n",
    "    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n",
    "    predicted_positives = np.sum(predicted_mask)\n",
    "    if predicted_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    return true_positives / predicted_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Loss Functions: done\n",
    "- dice coefficient: metric used to evaluate similarity between sets, particularly in image segmentation. Dice coeff is calculated to be 2 times the intersection of the ground truth and predicted, over ground truth plus predicted. \n",
    "$$\n",
    "\\text{Dice Coefficient} = \\frac{2 \\times |A \\cap B|}{|A| + |B|}\n",
    "$$\n",
    "\n",
    "- weighted binary cross entropy\n",
    "\n",
    "- BCE Dice loss \n",
    "regular dice loss:  \n",
    "$$ \n",
    "\\text{Dice Loss} = 1 - \\text{Dice Coefficient}\n",
    "$$  \n",
    "BCE dice loss adds dice loss and wBCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dice loss function calculator.\n",
    "    \n",
    "Args:\n",
    "    y_true (Tensor): \n",
    "    y_pred (Tensor):\n",
    "Returns:\n",
    "    (Tensor): Dice loss for each element of a batch.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch in method header\n",
    "    - changed K to torch throughout\n",
    "\"\"\"\n",
    "def dice_coef(y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "    smooth = 1e-6\n",
    "    y_true_f = torch.reshape(y_true, (BATCH_SIZE, -1))\n",
    "    y_pred_f = torch.reshape(y_pred, (BATCH_SIZE, -1))\n",
    "    intersection = torch.sum(y_true_f * y_pred_f, axis=1)\n",
    "    return 1 - (2. * intersection + smooth) / (torch.sum(y_true_f, axis=1) + torch.sum(y_pred_f, axis=1) + smooth)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates weighted binary cross entropy. The weights are fixed.\n",
    "    \n",
    "This can be useful for unbalanced catagories.\n",
    "\n",
    "Adjust the weights here depending on what is required.\n",
    "\n",
    "For example if there are 10x as many positive classes as negative classes,\n",
    "    if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives \n",
    "    will be penalize 10 times as much as false negatives.\n",
    "\n",
    "Args:\n",
    "    true (Tensor): Ground-truth values\n",
    "    pred (Tensor): Predited values\n",
    "    weight_zero (float): Weight of class 0 (no-fire)\n",
    "    weight_one (float): Weight of class 1 (fire)\n",
    "\n",
    "Returns: \n",
    "    (float) : value for weighted binary cross entropy\n",
    "CHANGES:\n",
    "    - changed tf to torch in method header\n",
    "    - changed K to torch throughout\n",
    "    - changed keras BCE method to torch.nn.functional.binary_cross_entropy\n",
    "    \n",
    "\"\"\"\n",
    "def weighted_bincrossentropy(true: torch.Tensor, pred: torch.Tensor, weight_zero: float = 0.01, weight_one: float = 1) -> float:\n",
    "  \n",
    "    # calculate the binary cross entropy\n",
    "    # using torch.nn.functional.binary_cross_entropy, set reduction='none' to keep individual losses in a tensor\n",
    "    # rather than taking mean \n",
    "    bin_crossentropy = F.binary_cross_entropy(true, pred, reduction='none')\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "    \n",
    "    return torch.mean(weighted_bin_crossentropy, axis=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "BCE loss function calculator.\n",
    "\n",
    "Args:\n",
    "    y_true (Tensor): \n",
    "    y_pred (Tensor):\n",
    "Returns:\n",
    "    (Tensor): Mean BCE Dice loss over a batch.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "    - originally returned keras.reduce_weighted_loss(loss), but without additional args all that did was \n",
    "      perform a sum operation. Replaced it with torch.sum since there is no torch equivalent to reduce_weighted_loss\n",
    "\"\"\"\n",
    "def bce_dice_loss(y_true: torch.Tensor, y_pred: torch.Tensor):    \n",
    "    y_true_f = torch.reshape(y_true, (BATCH_SIZE, -1))\n",
    "    y_pred_f = torch.reshape(y_pred, (BATCH_SIZE, -1))\n",
    "    return torch.sum(weighted_bincrossentropy(y_true_f, y_pred_f) + dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Evaluation Loop: done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads dataset according to file pattern and evaluates model's predictions on it.\n",
    "\n",
    "Parameters:\n",
    "    model (Callable[[tf.Tensor], tf.Tensor]): Function for model inference.\n",
    "    eval_dataset (tf.dataDataset): Dataset for evaluation.\n",
    "\n",
    "Returns:\n",
    "    Tuple[float, float, float, float]: IoU score, recall score, precision score and mean loss.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "    - in method header, imported DataLoader from torch.utils and changed  eval_dataset: tf.data.Dataset) to DataLoader\n",
    "    - changed tf.expand_dims(tf.cast(predictions, tf.float32), axis=-1) to predictions.float().unsqueeze(-1)\n",
    "    in losses.append\n",
    "\"\"\"\n",
    "def evaluate_model(prediction_function: Callable[[torch.Tensor], torch.Tensor],\n",
    "                   eval_dataset: DataLoader) -> Tuple[float, float, float, float]:\n",
    "    IoU_measures = []\n",
    "    recall_measures = []\n",
    "    precision_measures = []\n",
    "    losses = []\n",
    "    \n",
    "    for inputs, labels in tqdm(eval_dataset):\n",
    "        # Prediction shape (N, W, H)\n",
    "        predictions = prediction_function(inputs)\n",
    "        for i in range(inputs.shape[0]):\n",
    "            IoU_measures.append(IoU_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "            recall_measures.append(recall_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "            precision_measures.append(precision_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "        labels_cleared = torch.where(labels < 0, 0, labels)\n",
    "        losses.append(bce_dice_loss(labels_cleared, predictions.float().unsqueeze(-1)\n",
    "))\n",
    "            \n",
    "    mean_IoU = np.mean(IoU_measures)\n",
    "    mean_recall = np.mean(recall_measures)\n",
    "    mean_precision = np.mean(precision_measures)\n",
    "    mean_loss = np.mean(losses)\n",
    "    return mean_IoU, mean_recall, mean_precision, mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Technique\n",
    "## VII. Torch Model: done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers chosen for skips from NDWS were:  \n",
    "       a. 'block_1_expand_relu',   \n",
    "       b. 'block_3_expand_relu',   \n",
    "       c. 'block_6_expand_relu',   \n",
    "       d. 'block_13_expand_relu',  \n",
    "       e. 'block_16_project',  \n",
    "\n",
    "which matched to the following dimensions (from model.summary()):  \n",
    "        a. (16, 16, 96)  \n",
    "        b. (8, 8, 144)  \n",
    "        c. (4, 4, 192)  \n",
    "        d. (2, 2, 576)  \n",
    "        e. (1, 1, 320)  \n",
    "  \n",
    "equivalent layers in torch model, after adjusting model for 12   channel output, were (using forward hook to print sizes of   submodules):  \n",
    "        a. features[2].conv[0] -> (96, 16, 16)  \n",
    "        b. features[3].conv[0] -> (144, 8, 8)  \n",
    "        c. features[6].conv[0] -> (192, 4, 4)  \n",
    "        d. features[13].conv[0] -> (576, 2, 2)  \n",
    "        e. features[17] -> (320, 1, 1)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing: \n",
    "# tf.keras.applications.MobileNetV2(input_shape=[32, 32, 12], include_top=False, weights=None)\n",
    "class Downstack(nn.Module):\n",
    "    def __init__(self, input_channels, kernel_size, stride, padding):\n",
    "        super().__init__() # initialize the class as a pytorch module\n",
    "\n",
    "        self.base_model = mobilenet_v2(weights=None) # torch imp only takes weights as parameter\n",
    "        # torch auto runs the classifier in the forward pass so have to replace those layers with identity to\n",
    "        # get equivalent to include_top=False\n",
    "        self.base_model.classifier = nn.Identity() \n",
    "\n",
    "        # changing default input size from 3 (RGB) to 12 for wildfire images\n",
    "        self.base_model.features[0][0] = nn.Conv2d(\n",
    "            in_channels = input_channels,\n",
    "            out_channels = RES_BLOCK_INPUT_CHANNELS,\n",
    "            kernel_size = kernel_size,\n",
    "            stride = stride,\n",
    "            padding = padding,\n",
    "            bias = False\n",
    "        )\n",
    "\n",
    "        # replacing layer_names and base_model_outputs in keras\n",
    "        # since we needed to grab outputs at submodule layers and only needed 5 rn, \n",
    "        # easiest way was to use a forward hook fnc and manually register each layer\n",
    "        self.skips= []\n",
    "        def hook(module, input, output):\n",
    "            self.skips.append(output)\n",
    "\n",
    "        self.base_model.features[2].conv[0].register_forward_hook(hook) # eqv 'block_1_expand_relu'\n",
    "        self.base_model.features[3].conv[0].register_forward_hook(hook) # eqv 'block_3_expand_relu'\n",
    "        self.base_model.features[6].conv[0].register_forward_hook(hook) # eqv 'block_6_expand_relu'\n",
    "        self.base_model.features[13].conv[0].register_forward_hook(hook) # eqv 'block_13_expand_relu'\n",
    "        self.base_model.features[17].register_forward_hook(hook) # eqv 'block_16_project'\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.base_model(x)\n",
    "        return self.skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create upstack: replacing pix2pix.upsample layers\n",
    "# pix2pix layers are just a conv transpose layer, a batchnorm layer, and a relu layer \n",
    "# (dropout optional but not used in NDWS model)\n",
    "def upsample(input, output, kernel_size=3, stride=2, padding=1):\n",
    "    block = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=input, out_channels=output, kernel_size=kernel_size, \n",
    "                           stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(output),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    nn.init.normal_(block[0].weight, mean=0.0, std=0.02) #initializer?\n",
    "    return block    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the downstack and upsampler together to make u-net like \n",
    "# conv autoencoder structure\n",
    "class convAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super.__init__() # initialize as pytorch module\n",
    "\n",
    "        self.downstack = Downstack(input_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.upstack = nn.Sequential(\n",
    "                    upsample(1280, 512),\n",
    "                    upsample(512, 256),\n",
    "                    upsample(256, 128),\n",
    "                    upsample(128, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = self.downstack(x)\n",
    "        x = skips[-1] # last layer of skips is bottleneck; where upsampler starts\n",
    "        skips = reversed(skips[:-1]) # rearrange from deep->shallow, dropping the bottleneck\n",
    "        \n",
    "        # concatenate outputs of upstack and skips along channel dimension\n",
    "        for up, skip in zip(self.upstack, skips):\n",
    "            x = up(x)\n",
    "            x = torch.cat([x, skip], dim = 1) # dim = 1 is channels acc to torch ordering\n",
    "            \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Torch Training loop\n",
    " \n",
    "\n",
    "not finished converting! changes made so far:  \n",
    "- tf.data.Dataset to DataLoader in method header\n",
    "- tf.keras.optimizers.Adam() to torch.optim.Adam() for optimizer\n",
    "- tf to torch for .where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTrains a model using train dataset. (Save weights of model with best IoU)\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33;03m    - removed GradientTape() call, replace all gradient stuff with \"optimizer.zero_grad(), loss.backward(), optimizer.step()\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(model: \u001b[43mModel\u001b[49m, train_dataset: DataLoader, epochs:\u001b[38;5;28mint\u001b[39m=\u001b[32m10\u001b[39m) -> Tuple[List[\u001b[38;5;28mfloat\u001b[39m], List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m     19\u001b[39m     loss_fn = bce_dice_loss\n\u001b[32m     20\u001b[39m     optimizer = torch.optim.Adam()\n",
      "\u001b[31mNameError\u001b[39m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Trains a model using train dataset. (Save weights of model with best IoU)\n",
    "\n",
    "Args:\n",
    "    model (Model): Model to train.\n",
    "    train_dataset (Dataset): Training dataset.\n",
    "    epochs (int): Number of epochs\n",
    "Returns:\n",
    "    Tuple[List[float], List[float]]: Train losses and Validation losses\n",
    "\n",
    "CHANGES:\n",
    "    - tf.data.Dataset to DataLoader in method header\n",
    "    - tf.keras.optimizers.Adam() to torch.optim.Adam() for optimizer\n",
    "    - tf to torch for .where()\n",
    "    - removed GradientTape() call, replace all gradient stuff with \"optimizer.zero_grad(), loss.backward(), optimizer.step()\"\n",
    "\"\"\"\n",
    "\n",
    "def train_model(model: Model, train_dataset: DataLoader, epochs:int=10) -> Tuple[List[float], List[float]]:\n",
    "    loss_fn = bce_dice_loss\n",
    "    optimizer = torch.optim.Adam()\n",
    "    batch_losses = []\n",
    "    val_losses = []\n",
    "    best_IoU = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        # Iterate through the dataset\n",
    "        progress = tqdm(train_dataset)\n",
    "        for images, masks in progress:\n",
    "            #with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images, training=True)\n",
    "            label = torch.where(masks < 0, 0, masks)\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(label, predictions)\n",
    "            losses.append(loss.numpy())\n",
    "            progress.set_postfix({'batch_loss': loss.numpy()})\n",
    "\n",
    "            # Compute gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backware()\n",
    "            optimizer.step()\n",
    "            #gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            # Update the model's weights\n",
    "            #optimizer.apply_gradients(zip(gradients, model.trainable_variables)) <-- what here?\n",
    "\n",
    "        # Evaluate model\n",
    "        print(\"Evaluation...\")\n",
    "        IoU, recall, precision, val_loss = evaluate_model(lambda x: torch.where(model.predict(x) > 0.5, 1, 0)[:,:,:,0], validation_dataset)\n",
    "        print(\"Validation set metrics:\")\n",
    "        print(f\"Mean IoU: {IoU}\\nMean precision: {precision}\\nMean recall: {recall}\\nValidation loss: {val_loss}\\n\")\n",
    "        # Save best model\n",
    "        if IoU > best_IoU:\n",
    "            best_IoU = IoU\n",
    "            model.save_weights(\"best.h5\")\n",
    "        \n",
    "        # Print the loss for monitoring\n",
    "        print(f'Epoch: {epoch}, Train loss: {np.mean(losses)}')\n",
    "        batch_losses.append(np.mean(losses))\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Best model IoU: {best_IoU}\")\n",
    "    return batch_losses, val_losses\n",
    "\n",
    "# Set reproducability\n",
    "tf.random.set_seed(1337)\n",
    "\n",
    "segmentation_model = build_CNN_AE_model()\n",
    "train_losses, val_losses = train_model(segmentation_model, train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Plot Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "## X. Metrics on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XI. Comparision with statistical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XII. Inference on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cae-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
