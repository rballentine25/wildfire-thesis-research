{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "import torch.nn.functional as F # for bce loss function\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable, Tuple, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "     \n",
    "BATCH_SIZE = 32\n",
    "INPUT_CHANNELS = 12\n",
    "RES_BLOCK_INPUT_CHANNELS = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 32, 16, 16])\n",
      "1 torch.Size([2, 16, 16, 16])\n",
      "2 torch.Size([2, 24, 8, 8])\n",
      "3 torch.Size([2, 24, 8, 8])\n",
      "4 torch.Size([2, 32, 4, 4])\n",
      "5 torch.Size([2, 32, 4, 4])\n",
      "6 torch.Size([2, 32, 4, 4])\n",
      "7 torch.Size([2, 64, 2, 2])\n",
      "8 torch.Size([2, 64, 2, 2])\n",
      "9 torch.Size([2, 64, 2, 2])\n",
      "10 torch.Size([2, 64, 2, 2])\n",
      "11 torch.Size([2, 96, 2, 2])\n",
      "12 torch.Size([2, 96, 2, 2])\n",
      "13 torch.Size([2, 96, 2, 2])\n",
      "14 torch.Size([2, 160, 1, 1])\n",
      "15 torch.Size([2, 160, 1, 1])\n",
      "16 torch.Size([2, 160, 1, 1])\n",
      "17 torch.Size([2, 320, 1, 1])\n",
      "18 torch.Size([2, 1280, 1, 1])\n",
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(12, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Identity()\n",
      ")\n",
      "xxxxxxxxxxxxxxxxxxxxxxx\n",
      "Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "# replacing: \n",
    "# tf.keras.applications.MobileNetV2(input_shape=[32, 32, 12], include_top=False, weights=None)\n",
    "class Downstack(nn.Module):\n",
    "    def __init__(self, input_channels, kernel_size, stride, padding):\n",
    "        super().__init__() # initialize the class as a pytorch module\n",
    "\n",
    "        self.base_model = mobilenet_v2(weights=None) # torch imp only takes weights as parameter\n",
    "        # torch auto runs the classifier in the forward pass so have to replace those layers with identity to\n",
    "        # get equivalent to include_top=False\n",
    "        self.base_model.classifier = nn.Identity() \n",
    "\n",
    "        # changing default input size from 3 (RGB) to 12 for wildfire images\n",
    "        self.base_model.features[0][0] = nn.Conv2d(\n",
    "            in_channels = input_channels,\n",
    "            out_channels = RES_BLOCK_INPUT_CHANNELS,\n",
    "            kernel_size = kernel_size,\n",
    "            stride = stride,\n",
    "            padding = padding,\n",
    "            bias = False\n",
    "        )\n",
    "\n",
    "        layrs = torch.randn(2, 12, 32, 32)\n",
    "        for i, layer in enumerate(self.base_model.features):\n",
    "            layrs = layer(layrs)\n",
    "            print(i, layrs.shape)\n",
    "\n",
    "\n",
    "        self.base_model.eval()\n",
    "        print(self.base_model)\n",
    "        print(\"xxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "        print(self.base_model.features[2].conv[0][0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # return a dictionary of the output layers\n",
    "        pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    base = Downstack(12, 3, 2, 1)\n",
    "    \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create upstack: replacing pix2pix.upsample layers\n",
    "# pix2pix layers are just a conv transpose layer, a batchnorm layer, and a relu layer \n",
    "# (dropout optional but not used in NDWS model)\n",
    "def upsample(input, output, kernel_size=3, stride=2, padding=1):\n",
    "    block = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=input, out_channels=output, kernel_size=kernel_size, \n",
    "                           stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(output),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    nn.init.normal_(block[0].weight, mean=0.0, std=0.02) #initializer?\n",
    "    return block    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super.__init__() # initialize as pytorch module\n",
    "\n",
    "        downstack_model = Downstack(input_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        upstack = nn.Sequential(\n",
    "                    upsample(1280, 512),\n",
    "                    upsample(512, 256),\n",
    "                    upsample(256, 128),\n",
    "                    upsample(128, 64)\n",
    "        )\n",
    "\n",
    "        # up_dimensions = [# in  out\n",
    "        #                 [1280, 512], \n",
    "        #                 [512, 256], \n",
    "        #                 [256, 128], \n",
    "        #                 [128, 64],\n",
    "        #                 ]\n",
    "        # upstack_blocks = []\n",
    "        # for input, output in up_dimensions:\n",
    "        #     upstack_blocks.append(upsample(input, output))\n",
    "        # upstack = nn.Sequential(*upstack_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep\n",
    "## data visualization methods\n",
    "do we need these??? ^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics (DONE)\n",
    "- IoU: Intersection over Union. measures overlap between prediction region and actual (ground truth) region. Scores from 0 to 1, where 1 is perfect overlap and 0 is no overlap. Usually used to determine whether bounding box is correct\n",
    "- Recall\n",
    "- Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IoU metric\n",
    "Calculation of intersection over union metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): IoU metric value\n",
    "\n",
    "CHANGES: \n",
    "    - changed \"tf\" to \"torch\" in method header and real_mask line\n",
    "    - added comments\n",
    "\"\"\"\n",
    "def IoU_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float: \n",
    "    # replacing neg values: torch.where(condition, choose-True, choose-False)\n",
    "    # when the value is pos (>=0), keep the value from real_mastorch. otherwise, replace with 0\n",
    "    real_mask = torch.where(real_mask>=0, real_mask, 0)\n",
    "\n",
    "    # calculates the intersection and union between real and predicted by using a log AND and OR functions from numpy\n",
    "    intersection = np.logical_and(real_mask, predicted_mask)\n",
    "    union = np.logical_or(real_mask, predicted_mask)\n",
    "\n",
    "    # if there is no object in either mask (both are entirely 0s), return 1 since IoU for \n",
    "    # empty masks would be perfect\n",
    "    if np.sum(union) == 0:\n",
    "        return 1\n",
    "    \n",
    "    # else, calculate and return intersection over union (IoU)\n",
    "    return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculation of recall metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): recall metric value\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "\"\"\"\n",
    "def recall_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float:\n",
    "\n",
    "    real_mask = torch.where(real_mask < 0, 0, real_mask)\n",
    "    \n",
    "    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n",
    "    actual_positives = np.sum(real_mask)\n",
    "    if actual_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    return true_positives / actual_positives\n",
    "\n",
    "\"\"\"\n",
    "Calculation of precision metric.\n",
    "    \n",
    "Args:\n",
    "    real_mask (Tensor): Ground-truth mask\n",
    "    predicted_mask (Tensor): Mask predicted by model\n",
    "Returns:\n",
    "    (float): precision metric value\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "\"\"\"\n",
    "def precision_metric(real_mask: torch.Tensor, predicted_mask: torch.Tensor) -> float:\n",
    "    real_mask = torch.where(real_mask < 0, 0, real_mask)\n",
    "    \n",
    "    true_positives = np.sum(np.logical_and(real_mask, predicted_mask))\n",
    "    predicted_positives = np.sum(predicted_mask)\n",
    "    if predicted_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    return true_positives / predicted_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss functions (DONE)\n",
    "- dice coefficient: metric used to evaluate similarity between sets, particularly in image segmentation. Dice coeff is calculated to be 2 times the intersection of the ground truth and predicted, over ground truth plus predicted. \n",
    "$$\n",
    "\\text{Dice Coefficient} = \\frac{2 \\times |A \\cap B|}{|A| + |B|}\n",
    "$$\n",
    "\n",
    "- weighted binary cross entropy\n",
    "\n",
    "- BCE Dice loss \n",
    "regular dice loss:  \n",
    "$$ \\text{Dice Loss} = 1 - \\text{Dice Coefficient}$$  \n",
    "BCE dice loss adds dice loss and wBCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dice loss function calculator.\n",
    "    \n",
    "Args:\n",
    "    y_true (Tensor): \n",
    "    y_pred (Tensor):\n",
    "Returns:\n",
    "    (Tensor): Dice loss for each element of a batch.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch in method header\n",
    "    - changed K to torch throughout\n",
    "\"\"\"\n",
    "def dice_coef(y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "    smooth = 1e-6\n",
    "    y_true_f = torch.reshape(y_true, (BATCH_SIZE, -1))\n",
    "    y_pred_f = torch.reshape(y_pred, (BATCH_SIZE, -1))\n",
    "    intersection = torch.sum(y_true_f * y_pred_f, axis=1)\n",
    "    return 1 - (2. * intersection + smooth) / (torch.sum(y_true_f, axis=1) + torch.sum(y_pred_f, axis=1) + smooth)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates weighted binary cross entropy. The weights are fixed.\n",
    "    \n",
    "This can be useful for unbalanced catagories.\n",
    "\n",
    "Adjust the weights here depending on what is required.\n",
    "\n",
    "For example if there are 10x as many positive classes as negative classes,\n",
    "    if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives \n",
    "    will be penalize 10 times as much as false negatives.\n",
    "\n",
    "Args:\n",
    "    true (Tensor): Ground-truth values\n",
    "    pred (Tensor): Predited values\n",
    "    weight_zero (float): Weight of class 0 (no-fire)\n",
    "    weight_one (float): Weight of class 1 (fire)\n",
    "\n",
    "Returns: \n",
    "    (float) : value for weighted binary cross entropy\n",
    "CHANGES:\n",
    "    - changed tf to torch in method header\n",
    "    - changed K to torch throughout\n",
    "    - changed keras BCE method to torch.nn.functional.binary_cross_entropy\n",
    "    \n",
    "\"\"\"\n",
    "def weighted_bincrossentropy(true: torch.Tensor, pred: torch.Tensor, weight_zero: float = 0.01, weight_one: float = 1) -> float:\n",
    "  \n",
    "    # calculate the binary cross entropy\n",
    "    # using torch.nn.functional.binary_cross_entropy, set reduction='none' to keep individual losses in a tensor\n",
    "    # rather than taking mean \n",
    "    bin_crossentropy = F.binary_cross_entropy(true, pred, reduction='none')\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "    \n",
    "    return torch.mean(weighted_bin_crossentropy, axis=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "BCE loss function calculator.\n",
    "\n",
    "Args:\n",
    "    y_true (Tensor): \n",
    "    y_pred (Tensor):\n",
    "Returns:\n",
    "    (Tensor): Mean BCE Dice loss over a batch.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "    - originally returned keras.reduce_weighted_loss(loss), but without additional args all that did was \n",
    "      perform a sum operation. Replaced it with torch.sum since there is no torch equivalent to reduce_weighted_loss\n",
    "\"\"\"\n",
    "def bce_dice_loss(y_true: torch.Tensor, y_pred: torch.Tensor):    \n",
    "    y_true_f = torch.reshape(y_true, (BATCH_SIZE, -1))\n",
    "    y_pred_f = torch.reshape(y_pred, (BATCH_SIZE, -1))\n",
    "    return torch.sum(weighted_bincrossentropy(y_true_f, y_pred_f) + dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop: done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads dataset according to file pattern and evaluates model's predictions on it.\n",
    "\n",
    "Parameters:\n",
    "    model (Callable[[tf.Tensor], tf.Tensor]): Function for model inference.\n",
    "    eval_dataset (tf.dataDataset): Dataset for evaluation.\n",
    "\n",
    "Returns:\n",
    "    Tuple[float, float, float, float]: IoU score, recall score, precision score and mean loss.\n",
    "\n",
    "CHANGES:\n",
    "    - changed tf to torch\n",
    "    - in method header, imported DataLoader from torch.utils and changed  eval_dataset: tf.data.Dataset) to DataLoader\n",
    "    - changed tf.expand_dims(tf.cast(predictions, tf.float32), axis=-1) to predictions.float().unsqueeze(-1)\n",
    "    in losses.append\n",
    "\"\"\"\n",
    "def evaluate_model(prediction_function: Callable[[torch.Tensor], torch.Tensor],\n",
    "                   eval_dataset: DataLoader) -> Tuple[float, float, float, float]:\n",
    "    IoU_measures = []\n",
    "    recall_measures = []\n",
    "    precision_measures = []\n",
    "    losses = []\n",
    "    \n",
    "    for inputs, labels in tqdm(eval_dataset):\n",
    "        # Prediction shape (N, W, H)\n",
    "        predictions = prediction_function(inputs)\n",
    "        for i in range(inputs.shape[0]):\n",
    "            IoU_measures.append(IoU_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "            recall_measures.append(recall_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "            precision_measures.append(precision_metric(labels[i, :, :,  0], predictions[i, :, :]))\n",
    "        labels_cleared = torch.where(labels < 0, 0, labels)\n",
    "        losses.append(bce_dice_loss(labels_cleared, predictions.float().unsqueeze(-1)\n",
    "))\n",
    "            \n",
    "    mean_IoU = np.mean(IoU_measures)\n",
    "    mean_recall = np.mean(recall_measures)\n",
    "    mean_precision = np.mean(precision_measures)\n",
    "    mean_loss = np.mean(losses)\n",
    "    return mean_IoU, mean_recall, mean_precision, mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "from models import mobilenet_v2\n",
    "\n",
    "\n",
    "base_model = mobilenet_v2(weights=None)\n",
    "\n",
    "# setting classifier to Identity() removes the FC layers at end of classifier and replaces them with a \"placeholder\" operator\n",
    "# which doesn't manipulate the outputs at all. Equivalent to keras include_top=False\n",
    "base_model.classifier = nn.Identity() \n",
    "\n",
    "# from torchvision source code, default first layer for mobilenetv2 expects 3 input channels. have to modify this first layer to \n",
    "# take 12 input channels instead. https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py\n",
    "# [0][0] modifies first layer in the first block of the feature extractor layer array. \n",
    "# From source code, out_channels=32, norm_layer=batchnormd, activationlayer=relu6\n",
    "base_model.features[0][0] = ops.Conv2dNormActivation(12, 32, stride=2, padding=1, norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU6)\n",
    "\n",
    "#print(base_model)\n",
    "layer = base_model.get_submodule(\"features.2.conv.0.2\")\n",
    "print(layer)\n",
    "# for name, module in base_model.features.named_modules():\n",
    "#     if isinstance(module, nn.ReLU6):\n",
    "#         print(f\"Found ReLU6 layer at {name}\")\n",
    "\n",
    "# for name, module in base_model.named_modules():\n",
    "#     print(name, module)\n",
    "\n",
    "\n",
    "class ModMobileNetV2(nn.Module):\n",
    "    def __init__(self, input_channels=12, include_top=False):\n",
    "        super().__init__()\n",
    "        self.model = mobilenet_v2(weights=None)\n",
    "        # \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "\n",
    "def cnn_ae_model():\n",
    "    base_model = models.mobilenet_v2(weights=None, pretrained=False)\n",
    "\n",
    "    # setting classifier to Identity() removes the FC layers at end of classifier and replaces them with a \"placeholder\" operator\n",
    "    # which doesn't manipulate the outputs at all. Equivalent to keras include_top=False\n",
    "    base_model.classifier = nn.Identity() \n",
    "\n",
    "    # from torchvision source code, default first layer for mobilenetv2 expects 3 input channels. have to modify this first layer to \n",
    "    # take 12 input channels instead. https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv2.py\n",
    "    # [0][0] modifies first layer in the first block of the feature extractor layer array. \n",
    "    # From source code, out_channels=32, norm_layer=batchnormd, activationlayer=relu6\n",
    "    base_model.features[0][0] = ops.Conv2dNormActivation(12, 32, stride=2, padding=1, norm_layer=nn.BatchNorm2d, activation_layer=nn.ReLU6)\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Training loop\n",
    "### \n",
    "\n",
    "not finished converting! changes made so far:  \n",
    "- tf.data.Dataset to DataLoader in method header\n",
    "- tf.keras.optimizers.Adam() to torch.optim.Adam() for optimizer\n",
    "- tf to torch for .where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a model using train dataset. (Save weights of model with best IoU)\n",
    "\n",
    "Args:\n",
    "    model (Model): Model to train.\n",
    "    train_dataset (Dataset): Training dataset.\n",
    "    epochs (int): Number of epochs\n",
    "Returns:\n",
    "    Tuple[List[float], List[float]]: Train losses and Validation losses\n",
    "\n",
    "CHANGES:\n",
    "    - tf.data.Dataset to DataLoader in method header\n",
    "    - tf.keras.optimizers.Adam() to torch.optim.Adam() for optimizer\n",
    "    - tf to torch for .where()\n",
    "    - removed GradientTape() call, replace all gradient stuff with \"optimizer.zero_grad(), loss.backward(), optimizer.step()\"\n",
    "\"\"\"\n",
    "\n",
    "def train_model(model: Model, train_dataset: DataLoader, epochs:int=10) -> Tuple[List[float], List[float]]:\n",
    "    loss_fn = bce_dice_loss\n",
    "    optimizer = torch.optim.Adam()\n",
    "    batch_losses = []\n",
    "    val_losses = []\n",
    "    best_IoU = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        # Iterate through the dataset\n",
    "        progress = tqdm(train_dataset)\n",
    "        for images, masks in progress:\n",
    "            #with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(images, training=True)\n",
    "            label = torch.where(masks < 0, 0, masks)\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(label, predictions)\n",
    "            losses.append(loss.numpy())\n",
    "            progress.set_postfix({'batch_loss': loss.numpy()})\n",
    "\n",
    "            # Compute gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backware()\n",
    "            optimizer.step()\n",
    "            #gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            # Update the model's weights\n",
    "            #optimizer.apply_gradients(zip(gradients, model.trainable_variables)) <-- what here?\n",
    "\n",
    "        # Evaluate model\n",
    "        print(\"Evaluation...\")\n",
    "        IoU, recall, precision, val_loss = evaluate_model(lambda x: torch.where(model.predict(x) > 0.5, 1, 0)[:,:,:,0], validation_dataset)\n",
    "        print(\"Validation set metrics:\")\n",
    "        print(f\"Mean IoU: {IoU}\\nMean precision: {precision}\\nMean recall: {recall}\\nValidation loss: {val_loss}\\n\")\n",
    "        # Save best model\n",
    "        if IoU > best_IoU:\n",
    "            best_IoU = IoU\n",
    "            model.save_weights(\"best.h5\")\n",
    "        \n",
    "        # Print the loss for monitoring\n",
    "        print(f'Epoch: {epoch}, Train loss: {np.mean(losses)}')\n",
    "        batch_losses.append(np.mean(losses))\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"Best model IoU: {best_IoU}\")\n",
    "    return batch_losses, val_losses\n",
    "\n",
    "# Set reproducability\n",
    "tf.random.set_seed(1337)\n",
    "\n",
    "segmentation_model = build_CNN_AE_model()\n",
    "train_losses, val_losses = train_model(segmentation_model, train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cae-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
